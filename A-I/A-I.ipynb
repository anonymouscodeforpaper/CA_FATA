{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing import preprocessing,get_movies_aspect_matrix,dict_movie_aspect,viewed_matrix\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn.preprocessing as pp\n",
    "from compute_strength import film_strength\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = pd.read_csv('/home/jinfeng/Downloads/technique/dataset/context dataset/Mobile_Frappe/frappe/submission/recsys2023/data/train.csv')\n",
    "testset = pd.read_csv('/home/jinfeng/Downloads/technique/dataset/context dataset/Mobile_Frappe/frappe/submission/recsys2023/data/test.csv')\n",
    "trainset['cnt'] = (trainset['cnt'] + 1) * 2 + 1\n",
    "testset['cnt'] = (testset['cnt'] + 1) * 2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.0, 4.6222575010097575)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(trainset['cnt']),max(testset['cnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'meta_app_knowledge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmeta_app_knowledge\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'meta_app_knowledge' is not defined"
     ]
    }
   ],
   "source": [
    "meta_app_knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_app_knowledge = pd.read_csv('/home/jinfeng/Downloads/technique/dataset/context dataset/Mobile_Frappe/frappe/submission/recsys2023/data/meta_app.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hehe_test = trainset.merge(meta_app_knowledge,on='item')\n",
    "df_empty = testset.merge(meta_app_knowledge,on='item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-e39932f4636d>:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_all = hehe_test.append(df_empty)\n"
     ]
    }
   ],
   "source": [
    "df_all = hehe_test.append(df_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.rename(columns={'user':'userID','item':'itemID','cnt':'rating'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum = df_all.copy()\n",
    "movie_set = set(df_sum['itemID'])\n",
    "movie = df_sum[['itemID', 'category', 'downloads', 'language',\n",
    "                'price', 'rating']].loc[df_sum[['itemID', 'category', 'downloads', 'language',\n",
    "                                                'price', 'rating']].astype(str).drop_duplicates().index]\n",
    "movie.index = range(len(movie))\n",
    "movie = movie[['itemID', 'category', 'downloads', 'language',\n",
    "               'price', 'rating']].loc[movie[['itemID', 'category', 'downloads', 'language',\n",
    "                                              'price', 'rating']].astype(str).drop_duplicates().index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_dict = dict()\n",
    "train_ratings_dict = dict()\n",
    "\n",
    "train_ratings_dict[\"userID\"] = []\n",
    "train_ratings_dict[\"itemID\"] = []\n",
    "train_ratings_dict[\"rating\"] = []\n",
    "\n",
    "\n",
    "test_eva_dict = hehe_test.to_dict('records')\n",
    "for row in test_eva_dict[:]:\n",
    "    tuple_key = (row['user'],row['item'])\n",
    "    ratings_dict[tuple_key] = row['cnt']\n",
    "    train_ratings_dict[\"userID\"].append(row['user'])\n",
    "    train_ratings_dict[\"itemID\"].append(row['item'])\n",
    "    train_ratings_dict[\"rating\"].append(row['cnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_test_ratings_dict = dict()\n",
    "test_eva_dict = df_empty.to_dict('records')\n",
    "for row in test_eva_dict[:]:\n",
    "    if row['user'] not in compressed_test_ratings_dict:\n",
    "        compressed_test_ratings_dict[row['user']] = []\n",
    "    compressed_test_ratings_dict[row['user']].append((row['item'],row['cnt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userID', 'itemID', 'rating', 'daytime', 'weekday', 'isweekend',\n",
       "       'homework', 'weather', 'country', 'city', 'category', 'downloads',\n",
       "       'language', 'price', 'rating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-dcbc40360573>:4: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  test_eva_dict = movie.to_dict('records')\n"
     ]
    }
   ],
   "source": [
    "films = dict()\n",
    "\n",
    "\n",
    "test_eva_dict = movie.to_dict('records')\n",
    "for row in test_eva_dict[:]:\n",
    "    if row['itemID'] not in films:\n",
    "        films[row['itemID']] = dict()\n",
    "    films[row['itemID']]['category'] = [row['category']]\n",
    "    films[row['itemID']]['downloads'] = [row['downloads']]\n",
    "    films[row['itemID']]['language'] = [row['language']]\n",
    "    films[row['itemID']]['price'] = [row['price']]\n",
    "    films[row['itemID']]['rating'] = [row['rating']]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-7b9550262de4>:2: FutureWarning: In a future version, passing float-dtype values containing NaN and an integer dtype will raise IntCastingNaNError (subclass of ValueError) instead of silently ignoring the passed dtype. To retain the old behavior, call Series(arr) or DataFrame(arr) without passing a dtype.\n",
      "  movies_watched = pd.DataFrame.from_dict(\n"
     ]
    }
   ],
   "source": [
    "movies_watched = viewed_matrix(train_ratings_dict, films, 'netflix')\n",
    "movies_watched = pd.DataFrame.from_dict(\n",
    "    movies_watched, dtype='int64', orient='index').T\n",
    "movies_watched = movies_watched.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids_in_matrix = movies_watched.index.values\n",
    "movies_watched = movies_watched.T\n",
    "movies_watched = scipy.sparse.csc_matrix(movies_watched.values)\n",
    "normalized_matrix_by_column = pp.normalize(\n",
    "    movies_watched.tocsc(), norm='l2', axis=0)\n",
    "cosine_sims = normalized_matrix_by_column.T * normalized_matrix_by_column\n",
    "assert cosine_sims.shape[0] == cosine_sims.shape[1] == len(\n",
    "    user_ids_in_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = dict()\n",
    "for i in user_ids_in_matrix:\n",
    "    sims[i] = []\n",
    "cosine_sims = cosine_sims.todok().items()\n",
    "\n",
    "for ((row, col), sim) in cosine_sims:\n",
    "    if row != col:\n",
    "        sims[user_ids_in_matrix[row]].append(\n",
    "                (user_ids_in_matrix[col], sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 32 category (an example is 31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinfeng/Downloads/technique/dataset/context dataset/Mobile_Frappe/frappe/submission/recsys2023/A-I/processing.py:73: FutureWarning: In a future version, passing float-dtype values containing NaN and an integer dtype will raise IntCastingNaNError (subclass of ValueError) instead of silently ignoring the passed dtype. To retain the old behavior, call Series(arr) or DataFrame(arr) without passing a dtype.\n",
      "  movies_all_aspects_matrix = pd.DataFrame.from_dict(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 16 downloads (an example is 47)\n",
      "We have 28 language (an example is 74)\n",
      "We have 3 price (an example is 78)\n",
      "We have 4 rating (an example is 82)\n"
     ]
    }
   ],
   "source": [
    "category_in_db, movies_all_category_matrix = get_movies_aspect_matrix(\n",
    "    films, \"category\")\n",
    "downloads_in_db, movies_all_downloads_matrix = get_movies_aspect_matrix(\n",
    "    films, \"downloads\")\n",
    "language_in_db, movies_all_language_matrix = get_movies_aspect_matrix(\n",
    "    films, \"language\")\n",
    "price_in_db, movies_all_price_matrix = get_movies_aspect_matrix(\n",
    "    films, \"price\")\n",
    "rating_in_db, movies_all_rating_matrix = get_movies_aspect_matrix(\n",
    "    films, \"rating\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userID', 'itemID', 'rating', 'daytime', 'weekday', 'isweekend',\n",
       "       'homework', 'weather', 'country', 'city', 'category', 'downloads',\n",
       "       'language', 'price', 'rating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUR = 0.8\n",
    "MUC = 0.1\n",
    "MUD = 0.1\n",
    "MUL = 0.1\n",
    "MUP = 0.1\n",
    "MURR= 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for user_id, true_ratings in compressed_test_ratings_dict.items():\n",
    "    if true_ratings:\n",
    "        for (film_id, str_rating) in true_ratings:\n",
    "            str_rating = str_rating * 4.458668059764898 / 5\n",
    "            strength = film_strength(MUR, MUC, MUD, MUL, MUP, MURR, user_id, film_id, films, ratings_dict,\n",
    "                                     sims[user_id], movies_all_category_matrix, movies_all_downloads_matrix, movies_all_language_matrix,movies_all_price_matrix,movies_all_rating_matrix)\n",
    "            strength = strength * 4.458668059764898 / 5\n",
    "            predictions.append((float(str_rating), float(strength)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.1711929765078264, 0.9848455142451471)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_ratings = [x for (x, y) in predictions]\n",
    "predicted_ratings = [round(y) for (x, y) in predictions]\n",
    "sqrt(mean_squared_error(true_ratings, predicted_ratings)), mean_absolute_error(true_ratings, predicted_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>cnt</th>\n",
       "      <th>daytime</th>\n",
       "      <th>weekday</th>\n",
       "      <th>isweekend</th>\n",
       "      <th>homework</th>\n",
       "      <th>weather</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>category</th>\n",
       "      <th>downloads</th>\n",
       "      <th>language</th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>2470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>97</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>47</td>\n",
       "      <td>74</td>\n",
       "      <td>78</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>2470</td>\n",
       "      <td>1.350314</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>97</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>47</td>\n",
       "      <td>74</td>\n",
       "      <td>78</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>2470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>97</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>47</td>\n",
       "      <td>74</td>\n",
       "      <td>78</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>173</td>\n",
       "      <td>25</td>\n",
       "      <td>1.012735</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>97</td>\n",
       "      <td>257</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>56</td>\n",
       "      <td>76</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>324</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>79</td>\n",
       "      <td>237</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>56</td>\n",
       "      <td>76</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75768</th>\n",
       "      <td>436</td>\n",
       "      <td>3821</td>\n",
       "      <td>0.337578</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>78</td>\n",
       "      <td>233</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "      <td>56</td>\n",
       "      <td>76</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75769</th>\n",
       "      <td>121</td>\n",
       "      <td>3634</td>\n",
       "      <td>1.167829</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>97</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>47</td>\n",
       "      <td>74</td>\n",
       "      <td>78</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75770</th>\n",
       "      <td>92</td>\n",
       "      <td>1291</td>\n",
       "      <td>1.407677</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>73</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>56</td>\n",
       "      <td>76</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75771</th>\n",
       "      <td>293</td>\n",
       "      <td>3875</td>\n",
       "      <td>0.337578</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>99</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>47</td>\n",
       "      <td>74</td>\n",
       "      <td>78</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75772</th>\n",
       "      <td>325</td>\n",
       "      <td>884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>97</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>47</td>\n",
       "      <td>74</td>\n",
       "      <td>78</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75773 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user  item       cnt  daytime  weekday  isweekend  homework  weather  \\\n",
       "0        12  2470  0.000000        4       10         14        16       19   \n",
       "1        12  2470  1.350314        4       13         15        16       19   \n",
       "2        12  2470  0.000000        6       11         15        16       25   \n",
       "3       173    25  1.012735        6        8         15        17       25   \n",
       "4       324    25  0.000000        1       11         15        17       26   \n",
       "...     ...   ...       ...      ...      ...        ...       ...      ...   \n",
       "75768   436  3821  0.337578        1        7         14        17       19   \n",
       "75769   121  3634  1.167829        0        9         14        16       25   \n",
       "75770    92  1291  1.407677        3        9         14        17       25   \n",
       "75771   293  3875  0.337578        0        9         14        17       26   \n",
       "75772   325   884  0.000000        1       13         15        17       25   \n",
       "\n",
       "       country  city  category  downloads  language  price  rating  \n",
       "0           97   100        31         47        74     78      82  \n",
       "1           97   100        31         47        74     78      82  \n",
       "2           97   100        31         47        74     78      82  \n",
       "3           97   257         8         36        56     76      81  \n",
       "4           79   237         8         36        56     76      81  \n",
       "...        ...   ...       ...        ...       ...    ...     ...  \n",
       "75768       78   233        10         37        56     76      81  \n",
       "75769       97   100        31         47        74     78      82  \n",
       "75770       73   100        27         34        56     76      80  \n",
       "75771       99   100        31         47        74     78      82  \n",
       "75772       97   100        31         47        74     78      82  \n",
       "\n",
       "[75773 rows x 15 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hehe_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item = {}\n",
    "user_item_neg = {}\n",
    "\n",
    "for user in set(df_all['userID']):\n",
    "    if user not in user_item:\n",
    "        pos_df = hehe_test[hehe_test['user'] == user]\n",
    "        user_item[user] = set(pos_df['item'].values)\n",
    "for user,pos_item_set in user_item.items():\n",
    "    unwatched_set = movie_set - pos_item_set\n",
    "    if user not in user_item_neg:\n",
    "        user_item_neg[user] = set()\n",
    "    user_item_neg[user] = set(np.random.choice(list(unwatched_set), size=100, replace=False))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_i = 101\n",
    "\n",
    "\n",
    "def get_prediction_list(user, target, k):\n",
    "\n",
    "    item_neg = user_item_neg[user]\n",
    "    test_ratings_dict = dict()\n",
    "    test_ratings_dict[user] = []\n",
    "    items_list = []\n",
    "    for item in item_neg:\n",
    "        test_ratings_dict[user].append((item, 1))\n",
    "        items_list.append(item)\n",
    "    items_list.append(target)\n",
    "    test_ratings_dict[user].append((target, 1))\n",
    "    predictions = []\n",
    "    for user_id, true_ratings in test_ratings_dict.items():\n",
    "        if true_ratings:\n",
    "            for (film_id, str_rating) in true_ratings:\n",
    "                strength = film_strength(MUR, MUC, MUD, MUL, MUP, MURR, user_id, film_id, films, ratings_dict,\n",
    "                                         sims[user_id], movies_all_category_matrix, movies_all_downloads_matrix, movies_all_language_matrix, movies_all_price_matrix, movies_all_rating_matrix)\n",
    "                predictions.append((int(str_rating), strength))\n",
    "\n",
    "    predicted_ratings = [round(y) for (x, y) in predictions]\n",
    "\n",
    "    prediction_dict = dict(zip(items_list, predicted_ratings))\n",
    "    top_k = dic_order_value_and_get_key(prediction_dict, k)\n",
    "    return top_k, prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "def hr_ndcg():\n",
    "    hr1 = 0.0\n",
    "    ndcg1 = 0.0\n",
    "    hr2 = 0.0\n",
    "    ndcg2 = 0.0\n",
    "    test_eva_dict = df_empty.to_dict('records')\n",
    "    for row in tqdm(test_eva_dict[:]):\n",
    "        user = row['user']\n",
    "        target = row['item']\n",
    "        \n",
    "        \n",
    "        recommended_item_10,_ = get_prediction_list(user,target,10)\n",
    "        recommended_item_20,_ = get_prediction_list(user,target,20)\n",
    "        if target in recommended_item_10:\n",
    "            hr1 +=1\n",
    "            posi = recommended_item_10.index(target)\n",
    "            ndcg1 += 1 / math.log(posi + 2,2)\n",
    "        if target in recommended_item_20:\n",
    "            hr2 +=1\n",
    "            posi = recommended_item_20.index(target)\n",
    "            ndcg2 += 1 / math.log(posi + 2,2)\n",
    "    return hr1 / df_empty.shape[0], ndcg1 / df_empty.shape[0],hr2 / df_empty.shape[0], ndcg2 / df_empty.shape[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dic_order_value_and_get_key(dicts, count):\n",
    "    final_result = []\n",
    "    a = sorted(dicts.items(), key=lambda x: x[1], reverse=True)\n",
    "    a_dict = a[:count]\n",
    "    for l in a_dict:\n",
    "        final_result.append(l[0])\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18943/18943 [42:28:16<00:00,  8.07s/it]   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.001108588924668743,\n",
       " 0.0004425044595498827,\n",
       " 0.020429710183181123,\n",
       " 0.005327836664330952)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_ndcg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rank = movie.copy()\n",
    "movie_rank = movie_rank.iloc[:, :-2]\n",
    "movie_rank = pd.concat([movie_rank,movie.iloc[:,-1]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import LeakyReLU\n",
    "leaky = LeakyReLU(0.1)\n",
    "drop = torch.nn.Dropout(p=0.4)\n",
    "class aggregator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(aggregator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        #self.wei = torch.nn.Embedding(self.input_dim,self.output_dim)\n",
    "        #self.bias = torch.nn.Embedding(1,self.output_dim)\n",
    "\n",
    "    def forward(self, user, to_agg, rel):\n",
    "        '''\n",
    "        user: 128 * 64\n",
    "        rel: 64 * 5\n",
    "        to_agg: 128 * 5 * 64\n",
    "        '''\n",
    "        scores = torch.matmul(user, rel) # 128 * 5\n",
    "        scores = leaky(scores)\n",
    "        m = torch.nn.Softmax(dim=1) # 128 * 5\n",
    "        scores = m(scores) # 128 * 5\n",
    "        scores1 = scores.unsqueeze(1) #128 * 1 * 5\n",
    "        context_agg = torch.bmm(scores1, to_agg) # 128 * 1 * 64\n",
    "        return context_agg\n",
    "\n",
    "\n",
    "\n",
    "class context_aware_knowledge(nn.Module):\n",
    "    def __init__(self, n_users, n_contexts, n_rc, n_entity, n_kc, n_factors,context_or):\n",
    "        super().__init__()\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors)\n",
    "        self.context_factors = torch.nn.Embedding(n_contexts, n_factors)\n",
    "        self.relation_c = torch.nn.Embedding(n_factors, n_rc)\n",
    "        self.entity_factors = torch.nn.Embedding(n_entity, n_factors)\n",
    "        self.relation_k = torch.nn.Embedding(n_factors, n_kc) # 64 * 5\n",
    "        self.agg = aggregator(n_factors, n_factors)\n",
    "        self.context_or = context_or\n",
    "\n",
    "    def forward(self, user, contexts_index, entities_index):\n",
    "\n",
    "        entities = self.entity_factors(entities_index)  # 128 * 5 * 64\n",
    "        contexts = self.context_factors(contexts_index)  # 128 * 5 * 64\n",
    "        if self.context_or == True:\n",
    "            u_nei = self.agg(self.user_factors(user), contexts,\n",
    "                    self.relation_c.weight)  # 128 * 1 * 64\n",
    "            u_final = u_nei + self.user_factors(user).unsqueeze(1) # 128 * 1 * 64\n",
    "            u_final = leaky(u_final)\n",
    "        else:\n",
    "            u_final = self.user_factors(user)\n",
    "        importances = torch.matmul(u_final.squeeze(1), self.relation_k.weight) # 128 * 5\n",
    "        importances = leaky(importances)\n",
    "        m = torch.nn.Softmax(dim=1) # 128 * 5\n",
    "        importances = m(importances) # 128 * 5\n",
    "        scores = torch.bmm(entities,u_final.squeeze(1).unsqueeze(2)) # 128 * 5 * 1\n",
    "        scores_final = torch.bmm(importances.unsqueeze(1),scores) # 128 * 1 * 1\n",
    "        scores_final = scores_final.squeeze(2) # 128 * 1\n",
    "        scores_final = scores_final.squeeze(1) # 128,\n",
    "#         scores_final = scores.sum(1) / 5\n",
    "#         scores_final = scores_final.squeeze(1)\n",
    "        return scores_final,importances,scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/jinfeng/Downloads/technique/dataset/context dataset/Mobile_Frappe/frappe/submission/recsys2023/models/abalation/model_nocontextaverage0.005_256_5e-05_256.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_app_knowledge = pd.read_csv('/home/jinfeng/Downloads/technique/dataset/context dataset/Mobile_Frappe/frappe/submission/recsys2023/data/meta_app.csv')\n",
    "n_entities = max(meta_app_knowledge['rating']) + 1\n",
    "n_rel = meta_app_knowledge.shape[1] - 1\n",
    "df = pd.read_csv('/home/jinfeng/Downloads/technique/dataset/context dataset/Mobile_Frappe/frappe/submission/recsys2023/data/final_app.csv')\n",
    "n_cf = df.shape[1] - 3  # Here, we compute the number of contextual factors\n",
    "# Here, we compute the number of users\n",
    "n_users = len(df['user'].value_counts())\n",
    "# Here, we compute the number of items\n",
    "n_items = len(df['item'].value_counts())\n",
    "n_contexts = max(df['city']) + 1\n",
    "\n",
    "df_test = pd.read_csv('/home/jinfeng/Downloads/technique/dataset/context dataset/Mobile_Frappe/frappe/submission/recsys2023/data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = context_aware_knowledge(n_users, n_contexts, n_cf, n_entities, n_rel,256,True).to(DEVICE)\n",
    "load_params = torch.load(path)['model']\n",
    "model_params = model.state_dict()\n",
    "same_parsms = {k: v for k, v in load_params.items()\n",
    "               if k in model_params.keys()}\n",
    "model_params.update(same_parsms)\n",
    "\n",
    "model.load_state_dict(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f_save = open('to_user.pkl', 'wb')\n",
    "pickle.dump(user_item_neg, f_save)\n",
    "f_save.close()\n",
    " \n",
    "# # # 读取\n",
    "f_read = open('to_user.pkl', 'rb')\n",
    "user_item_neg = pickle.load(f_read)\n",
    "#print(dict2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item = {}\n",
    "user_item_neg = {}\n",
    "\n",
    "for user in set(df_all['userID']):\n",
    "    if user not in user_item:\n",
    "        pos_df = hehe_test[hehe_test['user'] == user]\n",
    "        user_item[user] = set(pos_df['item'].values)\n",
    "for user,pos_item_set in user_item.items():\n",
    "    unwatched_set = movie_set - pos_item_set\n",
    "    if user not in user_item_neg:\n",
    "        user_item_neg[user] = set()\n",
    "    user_item_neg[user] = set(np.random.choice(list(unwatched_set), size=100, replace=False))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18943/18943 [00:06<00:00, 3035.32it/s]\n"
     ]
    }
   ],
   "source": [
    "user_item_neg = {}\n",
    "i = 0\n",
    "test_eva_dict = df_empty.to_dict('records')\n",
    "for row in tqdm(test_eva_dict[:]):\n",
    "    user_item_neg[(i,row['user'])] = set(np.random.choice(list(movie_set-set([row['item']])), size=100, replace=False))\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_i = 101\n",
    "def get_prediction_list(model,i,user, target, contexts_index,entities_index,k):\n",
    "    item_neg = user_item_neg[(i,user)]\n",
    "    movie_rec = meta_app_knowledge[meta_app_knowledge['item'].isin(item_neg)]\n",
    "    entities_o = movie_rec.iloc[:, 1:].values\n",
    "    entities = np.insert(entities_o,0,values=entities_index,axis=0)\n",
    "    \n",
    "    items_o = movie_rec['item'].values\n",
    "    items = np.insert(items_o,0,np.array(target))\n",
    "    \n",
    "    user = np.array([user] * num_i)\n",
    "    user = torch.LongTensor(user).to(DEVICE)\n",
    "    entities = torch.LongTensor(entities).to(DEVICE)\n",
    "    contexts = np.tile(contexts_index,(num_i,1))\n",
    "    contexts = torch.LongTensor(contexts).to(DEVICE)\n",
    "    prediction,importances,scores = model(user, contexts, entities)\n",
    "    prediction = prediction.detach().numpy()\n",
    "    prediction_dict = dict(zip(items, prediction))\n",
    "    top_k = dic_order_value_and_get_key(prediction_dict,k)\n",
    "    return top_k,prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4739.33it/s]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for row in tqdm(test_eva_dict[:1]):\n",
    "    user = row['user']\n",
    "    target = row['item']\n",
    "    contexts_index = []\n",
    "    contexts_index.append(row['daytime'])\n",
    "    contexts_index.append(row['weekday'])\n",
    "    contexts_index.append(row['isweekend'])\n",
    "    contexts_index.append(row['homework'])\n",
    "    contexts_index.append(row['weather'])\n",
    "    contexts_index.append(row['country'])\n",
    "    contexts_index.append(row['city'])\n",
    "    contexts_index = np.array(contexts_index)\n",
    "    entities_index = []\n",
    "\n",
    "    entities_index.append(row['category'])\n",
    "    entities_index.append(row['downloads'])\n",
    "    entities_index.append(row['language'])\n",
    "    entities_index.append(row['price'])\n",
    "    entities_index.append(row['rating'])\n",
    "    entities_index = np.array(entities_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_item_10, prediction_dict_10= get_prediction_list(\n",
    "    model, i, user, target, contexts_index, entities_index, 10)\n",
    "recommended_item_20, prediction_dict_20 = get_prediction_list(\n",
    "    model, i, user, target, contexts_index, entities_index, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "def hr_ndcg(data,model):\n",
    "    hr1 = 0.0\n",
    "    ndcg1 = 0.0\n",
    "    hr2 = 0.0\n",
    "    ndcg2 = 0.0\n",
    "    test_eva_dict = df_empty.to_dict('records')\n",
    "    i = 0\n",
    "    for row in tqdm(test_eva_dict[:]):\n",
    "        user = row['user']\n",
    "        target = row['item']\n",
    "        contexts_index = []\n",
    "        contexts_index.append(row['daytime'])\n",
    "        contexts_index.append(row['weekday'])\n",
    "        contexts_index.append(row['isweekend'])\n",
    "        contexts_index.append(row['homework'])\n",
    "        contexts_index.append(row['weather'])\n",
    "        contexts_index.append(row['country'])\n",
    "        contexts_index.append(row['city'])\n",
    "        contexts_index = np.array(contexts_index)\n",
    "        entities_index = []\n",
    "        \n",
    "        entities_index.append(row['category'])\n",
    "        entities_index.append(row['downloads'])\n",
    "        entities_index.append(row['language'])\n",
    "        entities_index.append(row['price'])\n",
    "        entities_index.append(row['rating'])\n",
    "        entities_index = np.array(entities_index)\n",
    "        \n",
    "        \n",
    "        recommended_item_10,_ = get_prediction_list(model,i,user,target,contexts_index,entities_index,10)\n",
    "        recommended_item_20,_ = get_prediction_list(model,i,user,target,contexts_index,entities_index,20)\n",
    "        if target in recommended_item_10:\n",
    "            hr1 +=1\n",
    "            posi = recommended_item_10.index(target)\n",
    "            ndcg1 += 1 / math.log(posi + 2,2)\n",
    "        if target in recommended_item_20:\n",
    "            hr2 +=1\n",
    "            posi = recommended_item_20.index(target)\n",
    "            ndcg2 += 1 / math.log(posi + 2,2)\n",
    "        i = i + 1\n",
    "    return hr1 / data.shape[0], ndcg1 / data.shape[0],hr2 / data.shape[0], ndcg2 / data.shape[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/home/jinfeng/Downloads/technique/dataset/context dataset/Mobile_Frappe/frappe/submission/recsys2023/models/model_0.005_256_5e-05_256.pkl'\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = context_aware_knowledge(n_users, n_contexts, n_cf, n_entities, n_rel,256,True).to(DEVICE)\n",
    "load_params = torch.load(path)['model']\n",
    "model_params = model.state_dict()\n",
    "same_parsms = {k: v for k, v in load_params.items()\n",
    "               if k in model_params.keys()}\n",
    "model_params.update(same_parsms)\n",
    "\n",
    "model.load_state_dict(model_params)\n",
    "#hr_ndcg(df_empty,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.26648366151084835,\n",
       " 0.14949698722591728,\n",
       " 0.3940241777965475,\n",
       " 0.1815652247647183)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.26648366151084835,\n",
    " 0.14949698722591728,\n",
    " 0.3940241777965475,\n",
    " 0.1815652247647183)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_i = 101\n",
    "def get_prediction_list(model,i,user, target,contexts_index,k):\n",
    "    item_neg = user_item_neg[(i,user)]\n",
    "    items = list(item_neg)\n",
    "    items.append(target)\n",
    "    #movie_rec = meta_app_knowledge[meta_app_knowledge['item'].isin(item_neg)]\n",
    "    #movie_rec.index = range(1, len(movie_rec)+1)\n",
    "    #movie_rec.loc[0] = entities_index\n",
    "    user = np.array([user] * num_i)\n",
    "    user = torch.LongTensor(user).to(DEVICE)\n",
    "    #item = np.array([target] * num_i)\n",
    "    item = torch.LongTensor(items).to(DEVICE)\n",
    "    #entities = movie_rec.iloc[:, 1:].values\n",
    "    #entities = torch.LongTensor(entities).to(DEVICE)\n",
    "    contexts = np.tile(contexts_index,(num_i,1))\n",
    "    contexts = torch.LongTensor(contexts).to(DEVICE)\n",
    "    prediction = model(user, item, contexts)\n",
    "    prediction = prediction.detach().numpy()\n",
    "    prediction_dict = dict(zip(items, prediction))\n",
    "    top_k = dic_order_value_and_get_key(prediction_dict,k)\n",
    "    return top_k,prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def hr_ndcg(data,model):\n",
    "    hr1 = 0.0\n",
    "    ndcg1 = 0.0\n",
    "    hr2 = 0.0\n",
    "    ndcg2 = 0.0\n",
    "    test_eva_dict = df_empty.to_dict('records')\n",
    "    i = 0\n",
    "    for row in test_eva_dict[:]:\n",
    "        user = row['user']\n",
    "        target = row['item']\n",
    "        contexts_index = []\n",
    "        contexts_index.append(row['daytime'])\n",
    "        contexts_index.append(row['weekday'])\n",
    "        contexts_index.append(row['isweekend'])\n",
    "        contexts_index.append(row['homework'])\n",
    "        contexts_index.append(row['weather'])\n",
    "        contexts_index.append(row['country'])\n",
    "        contexts_index.append(row['city'])\n",
    "        contexts_index = np.array(contexts_index)\n",
    "#         entities_index = []\n",
    "#         entities_index.append(target)\n",
    "#         entities_index.append(row['category'])\n",
    "#         entities_index.append(row['downloads'])\n",
    "#         entities_index.append(row['language'])\n",
    "#         entities_index.append(row['price'])\n",
    "#         entities_index.append(row['rating'])\n",
    "#         entities_index = np.array(entities_index)\n",
    "        \n",
    "        \n",
    "        recommended_item_10,_ = get_prediction_list(model,i,user,target,contexts_index,10)\n",
    "        recommended_item_20,_ = get_prediction_list(model,i,user,target,contexts_index,20)\n",
    "        if target in recommended_item_10:\n",
    "            hr1 +=1\n",
    "            posi = recommended_item_10.index(target)\n",
    "            ndcg1 += 1 / math.log(posi + 2,2)\n",
    "        if target in recommended_item_20:\n",
    "            hr2 +=1\n",
    "            posi = recommended_item_20.index(target)\n",
    "            ndcg2 += 1 / math.log(posi + 2,2)\n",
    "        i = i + 1\n",
    "    return hr1 / data.shape[0], ndcg1 / data.shape[0],hr2 / data.shape[0], ndcg2 / data.shape[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuMF(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_contexts,mlp_factors,gmf_factors, layers):\n",
    "        super(NeuMF, self).__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.mlp_factors = mlp_factors\n",
    "        self.gmf_factors = gmf_factors\n",
    "        self.layers = layers\n",
    "        \n",
    "        self.mlp_user_factors = torch.nn.Embedding(n_users, mlp_factors)\n",
    "        self.mlp_item_factors = torch.nn.Embedding(n_items, mlp_factors)\n",
    "        self.mlp_context_factors = torch.nn.Embedding(n_contexts, mlp_factors)\n",
    "        \n",
    "        self.gmf_user_factors = torch.nn.Embedding(n_users, gmf_factors)\n",
    "        self.gmf_item_factors = torch.nn.Embedding(n_items, gmf_factors)\n",
    "        \n",
    "        self.MLP1 = nn.Sequential(nn.Linear(9 * mlp_factors, self.layers[0]))\n",
    "        self.MLP2 = nn.Sequential(nn.Linear(self.layers[0],self.layers[1]))\n",
    "        self.MLP3 = nn.Sequential(nn.Linear(self.layers[1],self.layers[2]))\n",
    "        #self.MLP4 = nn.Sequential(nn.Linear(self.layers[2],self.layers[3]))\n",
    "        \n",
    "        self.outlayer = nn.Sequential(nn.Linear(self.layers[2] + gmf_factors,1))\n",
    "        \n",
    "        \n",
    "    def forward(self, user_id, item_id,context_id):\n",
    "        GMF_user_embeddings = self.gmf_user_factors(user_id) ## 128 * 64\n",
    "        GMF_item_embeddings = self.gmf_item_factors(item_id) ## 128 * 64\n",
    "        GMF_merge_embedding = GMF_user_embeddings * GMF_item_embeddings ## 128 * 64\n",
    "        \n",
    "        \n",
    "        MLP_user_embeddings = self.mlp_user_factors(user_id) ## 128 * 64\n",
    "        MLP_item_embeddings = self.mlp_item_factors(item_id) ## 128 * 64\n",
    "        MLP_context_embeddings = self.mlp_user_factors(context_id)\n",
    "        MLP_merge_embedding = torch.cat((MLP_user_embeddings,MLP_item_embeddings),1) ## 128 * 128\n",
    "        MLP_context_embedding = torch.reshape(MLP_context_embeddings,(user_id.shape[0],-1))\n",
    "        MLP_merge_embedding = torch.concat((MLP_merge_embedding,MLP_context_embedding),1)\n",
    "        \n",
    "        \n",
    "        MLP_out1 = self.MLP1(MLP_merge_embedding) ## 128 * 64\n",
    "        MLP_out1 = torch.nn.ReLU()(MLP_out1)\n",
    "        \n",
    "        MLP_out2 = self.MLP2(MLP_out1) ## 128 * 32\n",
    "        MLP_out2 = torch.nn.ReLU()(MLP_out2)\n",
    "        \n",
    "        MLP_out3 = self.MLP3(MLP_out2) ## 128 * 16\n",
    "        MLP_out3 = torch.nn.ReLU()(MLP_out3)\n",
    "        \n",
    "        #MLP_out4 = self.MLP4(MLP_out3) ## 128 * 8\n",
    "        #MLP_out4 = torch.nn.ReLU()(MLP_out4)\n",
    "        \n",
    "        out = torch.cat((GMF_merge_embedding,MLP_out3),1)\n",
    "        \n",
    "        \n",
    "        out = self.outlayer(out)  ## 128 * 1\n",
    "        return out.squeeze(1)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def RMSE(data, model):\n",
    "#     users_index = data.iloc[:, 0].values\n",
    "#     users = torch.LongTensor(users_index).to(DEVICE)\n",
    "#     items_index = data.iloc[:, 1].values\n",
    "#     items = torch.LongTensor(items_index).to(DEVICE)\n",
    "#     context_index = data.iloc[:, 3:].values\n",
    "#     contexts = torch.LongTensor(context_index).to(DEVICE)\n",
    "    \n",
    "    \n",
    "#     rating = torch.FloatTensor(data.iloc[:, 2].values).to(DEVICE)\n",
    "#     prediction= model(users, items,contexts)\n",
    "#     rmse = loss_func(prediction, rating)\n",
    "#     mae = torch.nn.L1Loss()(prediction, rating)\n",
    "#     return rmse ** 0.5,mae\n",
    "# path = '/home/jinfeng/Downloads/technique/dataset/context dataset/Mobile_Frappe/frappe/submission/recsys2023/models/model_neumf_contexts.pkl'\n",
    "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model = NeuMF(n_users, n_items,n_contexts, mlp_factors,gmf_factors, layers).to(DEVICE)\n",
    "# load_params = torch.load(path)['model']\n",
    "# model_params = model.state_dict()\n",
    "# same_parsms = {k: v for k, v in load_params.items()\n",
    "#                if k in model_params.keys()}\n",
    "# model_params.update(same_parsms)\n",
    "# model.load_state_dict(model_params)\n",
    "# RMSE(df_empty,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6222575010097575"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df_empty['cnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4054795966847912,\n",
       " 0.20809070671672492,\n",
       " 0.5722430449242464,\n",
       " 0.25035328556042724)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_factors = 8\n",
    "gmf_factors = 32 \n",
    "layers = [16,8,4]\n",
    "path = '/home/jinfeng/Downloads/technique/dataset/context dataset/Mobile_Frappe/frappe/submission/recsys2023/models/model_neumf_contexts.pkl'\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = NeuMF(n_users, n_items,n_contexts, mlp_factors,gmf_factors, layers).to(DEVICE)\n",
    "load_params = torch.load(path)['model']\n",
    "model_params = model.state_dict()\n",
    "same_parsms = {k: v for k, v in load_params.items()\n",
    "               if k in model_params.keys()}\n",
    "model_params.update(same_parsms)\n",
    "\n",
    "model.load_state_dict(model_params)\n",
    "\n",
    "hr_ndcg(df_test,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuMF(nn.Module):\n",
    "    def __init__(self, n_users, n_items, mlp_factors,gmf_factors, layers):\n",
    "        super(NeuMF, self).__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.mlp_factors = mlp_factors\n",
    "        self.gmf_factors = gmf_factors\n",
    "        self.layers = layers\n",
    "        \n",
    "        self.mlp_user_factors = torch.nn.Embedding(n_users, mlp_factors)\n",
    "        self.mlp_item_factors = torch.nn.Embedding(n_items, mlp_factors)\n",
    "        \n",
    "        self.gmf_user_factors = torch.nn.Embedding(n_users, gmf_factors)\n",
    "        self.gmf_item_factors = torch.nn.Embedding(n_items, gmf_factors)\n",
    "        \n",
    "        self.MLP1 = nn.Sequential(nn.Linear(2 * mlp_factors, self.layers[0]))\n",
    "        self.MLP2 = nn.Sequential(nn.Linear(self.layers[0],self.layers[1]))\n",
    "        self.MLP3 = nn.Sequential(nn.Linear(self.layers[1],self.layers[2]))\n",
    "        #self.MLP4 = nn.Sequential(nn.Linear(self.layers[2],self.layers[3]))\n",
    "        \n",
    "        self.outlayer = nn.Sequential(nn.Linear(self.layers[2] + gmf_factors,1))\n",
    "        \n",
    "        \n",
    "    def forward(self, user_id, item_id):\n",
    "        GMF_user_embeddings = self.gmf_user_factors(user_id) ## 128 * 64\n",
    "        GMF_item_embeddings = self.gmf_item_factors(item_id) ## 128 * 64\n",
    "        GMF_merge_embedding = GMF_user_embeddings * GMF_item_embeddings ## 128 * 64\n",
    "        \n",
    "        \n",
    "        MLP_user_embeddings = self.mlp_user_factors(user_id) ## 128 * 64\n",
    "        MLP_item_embeddings = self.mlp_item_factors(item_id) ## 128 * 64\n",
    "        MLP_merge_embedding = torch.cat((MLP_user_embeddings,MLP_item_embeddings),1) ## 128 * 128\n",
    "        \n",
    "        \n",
    "        MLP_out1 = self.MLP1(MLP_merge_embedding) ## 128 * 64\n",
    "        MLP_out1 = torch.nn.ReLU()(MLP_out1)\n",
    "        \n",
    "        MLP_out2 = self.MLP2(MLP_out1) ## 128 * 32\n",
    "        MLP_out2 = torch.nn.ReLU()(MLP_out2)\n",
    "        \n",
    "        MLP_out3 = self.MLP3(MLP_out2) ## 128 * 16\n",
    "        MLP_out3 = torch.nn.ReLU()(MLP_out3)\n",
    "        \n",
    "        #MLP_out4 = self.MLP4(MLP_out3) ## 128 * 8\n",
    "        #MLP_out4 = torch.nn.ReLU()(MLP_out4)\n",
    "        \n",
    "        out = torch.cat((GMF_merge_embedding,MLP_out3),1)\n",
    "        \n",
    "        \n",
    "        out = self.outlayer(out)  ## 128 * 1\n",
    "        return out.squeeze(1)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_i = 101\n",
    "def get_prediction_list(model,i,user, target,k):\n",
    "    item_neg = user_item_neg[(i,user)]\n",
    "    items = list(item_neg)\n",
    "    items.append(target)\n",
    "    #movie_rec = meta_app_knowledge[meta_app_knowledge['item'].isin(item_neg)]\n",
    "    #movie_rec.index = range(1, len(movie_rec)+1)\n",
    "    #movie_rec.loc[0] = entities_index\n",
    "    user = np.array([user] * num_i)\n",
    "    user = torch.LongTensor(user).to(DEVICE)\n",
    "    #item = np.array([target] * num_i)\n",
    "    item = torch.LongTensor(items).to(DEVICE)\n",
    "    #entities = movie_rec.iloc[:, 1:].values\n",
    "    #entities = torch.LongTensor(entities).to(DEVICE)\n",
    "    #contexts = np.tile(contexts_index,(num_i,1))\n",
    "    #contexts = torch.LongTensor(contexts).to(DEVICE)\n",
    "    prediction = model(user, item)\n",
    "    prediction = prediction.detach().numpy()\n",
    "    prediction_dict = dict(zip(items, prediction))\n",
    "    top_k = dic_order_value_and_get_key(prediction_dict,k)\n",
    "    return top_k,prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def hr_ndcg(data,model):\n",
    "    hr1 = 0.0\n",
    "    ndcg1 = 0.0\n",
    "    hr2 = 0.0\n",
    "    ndcg2 = 0.0\n",
    "    test_eva_dict = df_empty.to_dict('records')\n",
    "    i = 0.0\n",
    "    for row in tqdm(test_eva_dict[:]):\n",
    "        user = row['user']\n",
    "        target = row['item']\n",
    "#         contexts_index = []\n",
    "#         contexts_index.append(row['daytime'])\n",
    "#         contexts_index.append(row['weekday'])\n",
    "#         contexts_index.append(row['isweekend'])\n",
    "#         contexts_index.append(row['homework'])\n",
    "#         contexts_index.append(row['weather'])\n",
    "#         contexts_index.append(row['country'])\n",
    "#         contexts_index.append(row['city'])\n",
    "#         contexts_index = np.array(contexts_index)\n",
    "#         entities_index = []\n",
    "#         entities_index.append(target)\n",
    "#         entities_index.append(row['category'])\n",
    "#         entities_index.append(row['downloads'])\n",
    "#         entities_index.append(row['language'])\n",
    "#         entities_index.append(row['price'])\n",
    "#         entities_index.append(row['rating'])\n",
    "#         entities_index = np.array(entities_index)\n",
    "        \n",
    "        \n",
    "        recommended_item_10,_ = get_prediction_list(model,i,user,target,10)\n",
    "        recommended_item_20,_ = get_prediction_list(model,i,user,target,20)\n",
    "        if target in recommended_item_10:\n",
    "            hr1 +=1\n",
    "            posi = recommended_item_10.index(target)\n",
    "            ndcg1 += 1 / math.log(posi + 2,2)\n",
    "        if target in recommended_item_20:\n",
    "            hr2 +=1\n",
    "            posi = recommended_item_20.index(target)\n",
    "            ndcg2 += 1 / math.log(posi + 2,2)\n",
    "        i = i + 1\n",
    "    return hr1 / data.shape[0], ndcg1 / data.shape[0],hr2 / data.shape[0], ndcg2 / data.shape[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18943/18943 [00:12<00:00, 1477.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5273715884495592,\n",
       " 0.2867889354701134,\n",
       " 0.6723327878371957,\n",
       " 0.32370759217578143)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/home/jinfeng/Downloads/technique/dataset/context dataset/Mobile_Frappe/frappe/submission/recsys2023/models/model_neumf.pkl'\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = NeuMF(n_users, n_items, mlp_factors,gmf_factors, layers).to(DEVICE)\n",
    "load_params = torch.load(path)['model']\n",
    "model_params = model.state_dict()\n",
    "same_parsms = {k: v for k, v in load_params.items()\n",
    "               if k in model_params.keys()}\n",
    "model_params.update(same_parsms)\n",
    "\n",
    "model.load_state_dict(model_params)\n",
    "hr_ndcg(df_test,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "    def __init__(self, n_users, n_items,n_factors):\n",
    "        super().__init__()\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors)\n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors)\n",
    "    def forward(self, user, item):\n",
    "        u_final = self.user_factors(user).unsqueeze(1)\n",
    "        i_final = self.item_factors(item).unsqueeze(1)\n",
    "        u_final = drop(u_final)\n",
    "        i_final = drop(i_final)\n",
    "        return (u_final * i_final).sum(2).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18943/18943 [00:11<00:00, 1705.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4317162012352848,\n",
       " 0.19028969251812042,\n",
       " 0.6723327878371957,\n",
       " 0.2510244252670824)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/home/jinfeng/Downloads/technique/dataset/context dataset/Mobile_Frappe/frappe/submission/recsys2023/models/model_mf.pkl'\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = MF(n_users, n_items,256).to(DEVICE)\n",
    "load_params = torch.load(path)['model']\n",
    "model_params = model.state_dict()\n",
    "same_parsms = {k: v for k, v in load_params.items()\n",
    "               if k in model_params.keys()}\n",
    "model_params.update(same_parsms)\n",
    "\n",
    "model.load_state_dict(model_params)\n",
    "\n",
    "hr_ndcg(df_test,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>cnt</th>\n",
       "      <th>daytime</th>\n",
       "      <th>weekday</th>\n",
       "      <th>isweekend</th>\n",
       "      <th>homework</th>\n",
       "      <th>weather</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>356</td>\n",
       "      <td>314</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>97</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>1115</td>\n",
       "      <td>-0.369038</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>102</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>38</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264</td>\n",
       "      <td>282</td>\n",
       "      <td>-0.894897</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>97</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>264</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>44</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18938</th>\n",
       "      <td>107</td>\n",
       "      <td>319</td>\n",
       "      <td>-0.589835</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>48</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18939</th>\n",
       "      <td>209</td>\n",
       "      <td>49</td>\n",
       "      <td>0.141393</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>97</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18940</th>\n",
       "      <td>88</td>\n",
       "      <td>844</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>36</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18941</th>\n",
       "      <td>95</td>\n",
       "      <td>550</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18942</th>\n",
       "      <td>105</td>\n",
       "      <td>880</td>\n",
       "      <td>-1.026149</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>93</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18943 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user  item       cnt  daytime  weekday  isweekend  homework  weather  \\\n",
       "0       356   314 -1.500000        2        9         14        17       19   \n",
       "1        25  1115 -0.369038        1       12         15        17       25   \n",
       "2        90   102 -1.500000        1       10         14        17       21   \n",
       "3       264   282 -0.894897        0        9         14        17       21   \n",
       "4        33   264 -1.500000        4        8         15        17       19   \n",
       "...     ...   ...       ...      ...      ...        ...       ...      ...   \n",
       "18938   107   319 -0.589835        6        7         14        17       19   \n",
       "18939   209    49  0.141393        2       11         15        17       25   \n",
       "18940    88   844 -1.500000        5        8         15        17       19   \n",
       "18941    95   550 -1.500000        1       10         14        16       25   \n",
       "18942   105   880 -1.026149        2       11         15        17       22   \n",
       "\n",
       "       country  city  \n",
       "0           97   100  \n",
       "1           80   100  \n",
       "2           38   100  \n",
       "3           97   100  \n",
       "4           44   146  \n",
       "...        ...   ...  \n",
       "18938       48   139  \n",
       "18939       97   100  \n",
       "18940       36   125  \n",
       "18941       36   100  \n",
       "18942       93   250  \n",
       "\n",
       "[18943 rows x 10 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
